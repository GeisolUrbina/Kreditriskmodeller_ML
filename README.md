# üß† Kreditriskmodeller med maskininl√§rning

Detta projekt syftar till att bygga, analysera och j√§mf√∂ra maskininl√§rningsmodeller f√∂r att **f√∂ruts√§ga kreditrisk** ‚Äì n√§rmare best√§mt sannolikheten att en kund som beviljats l√•n g√•r i default (betalningsinst√§llelse). Arbetet √§r utf√∂rt p√• **syntetiskt genererad data**, vilket m√∂jligg√∂r full kontroll och insyn i variabler och beroenden.



## Datam√§ngd

Projektet anv√§nder en syntetisk datam√§ngd: [`synthetic_credit_data.csv`](synthetic_credit_data.csv), skapad specifikt f√∂r denna studie. Datat inneh√•ller fiktiva men realistiskt konstruerade kundprofiler, inklusive:

- Demografiska faktorer: √•lder, inkomst, anst√§llningsstatus, boendeform  
- Finansiella faktorer: kreditpo√§ng, l√•nebelopp, DTI (debt-to-income)  
- Historik: antal missade betalningar, kundrelationens l√§ngd  
- M√•lvariabel: `default` (1 = betalningsinst√§llelse, 0 = betalar tillbaka)

Endast kunder som **beviljats l√•n (`has_loan == 1`)** ing√•r i modelleringen.



## Projektstruktur

Projektet √§r organiserat i flera Jupyter Notebooks som representerar olika faser i analysen:

1. [`EDA.ipynb`](EDA.ipynb)  
   ‚Üí **Exploratory Data Analysis** (EDA) f√∂r att f√∂rst√• data, identifiera m√∂nster, utv√§rdera datakvalitet och f√∂rbereda inf√∂r modellering.

2. [`multicollinearity_analysis.ipynb`](multicollinearity_analysis.ipynb)  
   ‚Üí Unders√∂ker **multikollinearitet** med hj√§lp av Variance Inflation Factor (VIF), f√∂r att s√§kerst√§lla robusthet i regressionsmodellen.

3. [`Kreditriskmodell_ML.ipynb`](Kreditriskmodell_ML.ipynb)  
   ‚Üí Tr√§nar och utv√§rderar flera modeller (Logistic Regression, Random Forest, XGBoost).  
   ‚Üí Cross-validation, kalibrering, threshold-tuning och utv√§rdering p√• testdata ing√•r.

4. [`Logreg_model_kreditrisk.ipynb`](Logreg_model_kreditrisk.ipynb)  
   ‚Üí Fokus p√• den **f√∂rb√§ttrade logistiska regressionsmodellen**, inklusive:  
     - Feature engineering  
     - ElasticNet regularisering  
     - Kalibrering (Isotonic)  
     - Tolkning av koefficienter  
     - Slutlig utv√§rdering p√• testset

---

## üìà Resultat√∂versikt

| Modell         | ROC AUC | Recall | Precision | F1-score | Brier |
|----------------|---------|--------|-----------|----------|--------|
| Baseline       | 0.692   | 26.8%  | 53.6%     | 0.357    | 0.173  |
| F√∂rb√§ttrad LogReg | 0.943   | 56.4%  | 33.7%     | 0.422    | 0.039  |

Den f√∂rb√§ttrade modellen visade **mycket h√∂gre rangordningsf√∂rm√•ga**, b√§ttre kalibrerade sannolikheter, samt en b√§ttre balans mellan recall och precision.

---

## üìÅ √ñvriga filer

- `models/`: Tr√§nade och kalibrerade modeller sparade som `.joblib`
- `reports/`: JSON-filer med utv√§rderingsresultat fr√•n testdata
- `requirements.txt`: Pythonpaket som kr√§vs f√∂r att √•terskapa milj√∂n

---

##  Slutsats

Logistisk regression, trots sin enkelhet, visade sig vara en **mycket stark modell** f√∂r kreditrisk ‚Äì s√§rskilt i kombination med:

- Tydlig feature engineering
- Kalibrering av sannolikheter
- Threshold-tuning utifr√•n verksamhetsm√•l

Genom att j√§mf√∂ra modeller och fokusera p√• tolkning, noggrannhet och √•terkallning har vi uppn√•tt en modell som √§r b√•de **praktiskt anv√§ndbar och tekniskt robust**.



---


*Detta projekt √§r en del av kursen F√∂rdjupad Python ‚Äì Data Science vid EC Utbildning, 2025.*


